{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I07FwHoBaqk"
   },
   "source": [
    "# Programação Paralela Híbrida: MPI + OpenMP Offloading\n",
    "\n",
    "Autores: *Calebe P. Bianchini, Evaldo B. Costa, Gabriel P. Silva*\n",
    "\n",
    "### Setup rápido do ambiente\n",
    "\n",
    "(não esqueça de selecionar um Runtime adequado, com GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37856,
     "status": "ok",
     "timestamp": 1729834697813,
     "user": {
      "displayName": "Calebe Bianchini",
      "userId": "11471636135648050191"
     },
     "user_tz": 180
    },
    "id": "5l0RumDHAxyr",
    "outputId": "b2521e0b-41f8-40fc-b4d0-21a1cbd4a5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 13.1.0-8ubuntu1~22.04) 13.1.0\n",
      "Copyright (C) 2023 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "mpicc: Open MPI 4.1.2 (Language: C)\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n",
      "Fri Oct 25 05:38:20 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   51C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!add-apt-repository -y ppa:ubuntu-toolchain-r/test &> /dev/null\n",
    "!apt install -y gcc-13 g++-13 gcc-13-offload-nvptx libgomp1 &> /dev/null\n",
    "!apt install openmpi-bin openmpi-common libopenmpi-dev &> /dev/null\n",
    "!ln -sfnv /usr/bin/gcc-13 /usr/bin/gcc &> /dev/null\n",
    "!gcc --version\n",
    "!mpicc --showme:version\n",
    "!nvcc --version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-IHagXTLSnM"
   },
   "source": [
    "## Problema do PI\n",
    "\n",
    "1. Criação do arquivo de código-fonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 867,
     "status": "ok",
     "timestamp": 1729836647436,
     "user": {
      "displayName": "Calebe Bianchini",
      "userId": "11471636135648050191"
     },
     "user_tz": 180
    },
    "id": "svasOPN2F91p",
    "outputId": "26c40137-cd28-49a3-d893-c7b5f612deed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pi.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile pi.c\n",
    "\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "#include <math.h>\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "  MPI_Init(&argc, &argv);\n",
    "  int rank, size;\n",
    "  long int num_steps = 10000000000; // Número de passos para a integração\n",
    "  double step = 1.0 / (double) num_steps;\n",
    "  double pi = 0.0;\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "  if(size < 2) {\n",
    "    MPI_Abort(MPI_COMM_WORLD, -1);\n",
    "  }\n",
    "  long int my_num_steps = num_steps / size;\n",
    "  long int i_begin = rank * my_num_steps;\n",
    "  long int i_end = i_begin + my_num_steps;\n",
    "  // Versão encadeada de execução na GPU, controlada por mensagens MPI a partir do rank 0\n",
    "  if(!rank) {\n",
    "    double begin, end;\n",
    "    printf(\"Iniciando o calculo do Pi no rank: %d\\n\", rank);\n",
    "    begin = omp_get_wtime();\n",
    "  #pragma omp target data map(tofrom: pi) map(to:num_steps, step) device(1)// Diretiva para offloading para a GPU\n",
    "  #pragma omp target teams distribute parallel for reduction(+:pi) // Paralelização com OpenMP no rank 0\n",
    "    for (long int i = i_begin; i < i_end; i++) {\n",
    "          double x = (i + 0.5) * step;\n",
    "          pi += 4.0 / (double) (1.0 + x * x);\n",
    "    }\n",
    "    printf(\"Valor parcial do Pi: %2.15f\\n\", pi*step);\n",
    "    MPI_Send(&pi, 1, MPI_DOUBLE, 1, num_steps, MPI_COMM_WORLD);\n",
    "    MPI_Recv(&pi, 1, MPI_DOUBLE, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "    pi *= step;\n",
    "    end = omp_get_wtime();\n",
    "    printf(\"Valor de Pi calculado: %2.15f\\n\", pi);\n",
    "    printf(\"Tempo de execução: %f segundos\\n\", end - begin);\n",
    "  } else {\n",
    "    MPI_Recv(&pi, 1, MPI_DOUBLE, rank-1, MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "    printf(\"Continuando o calculo do Pi no rank: %d\\n\", rank);\n",
    "  #pragma omp target data map(tofrom: pi) map(to:num_steps, step) device(1)// Diretiva para offloading para a GPU\n",
    "  #pragma omp target teams distribute parallel for reduction(+:pi) // Paralelização com OpenMP nos demais ranks\n",
    "     for (long int i = i_begin; i < i_end; i++) {\n",
    "          double x = (i + 0.5) * step;\n",
    "          pi += 4.0 / (double) (1.0 + x * x);\n",
    "     }\n",
    "     printf(\"Valor parcial do Pi: %2.15f\\n\", pi*step);\n",
    "     MPI_Send(&pi, 1, MPI_DOUBLE, (rank+1)%size, num_steps, MPI_COMM_WORLD);\n",
    "  }\n",
    "  MPI_Finalize();\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPhi1zfrLZgz"
   },
   "source": [
    "2. Compilação com MPI e OpenMP _offload_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729836650840,
     "user": {
      "displayName": "Calebe Bianchini",
      "userId": "11471636135648050191"
     },
     "user_tz": 180
    },
    "id": "_sIbeYz8KMdW"
   },
   "outputs": [],
   "source": [
    "!mpicc -fopenmp -fno-lto -fstack-protector pi.c -Wall -o pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMvSENLFQFg4"
   },
   "source": [
    "3. Executando o cálculo do Pi com OpenMP Offloading e de forma cadenciada controlada por mensagens MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74657,
     "status": "ok",
     "timestamp": 1729836745969,
     "user": {
      "displayName": "Calebe Bianchini",
      "userId": "11471636135648050191"
     },
     "user_tz": 180
    },
    "id": "3g2N6-hfKtZu",
    "outputId": "0aaf1341-8565-45cd-a1cf-dc2cfc180a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o calculo do Pi no rank: 0\n",
      "Valor parcial do Pi: 0.979914652507362\n",
      "Continuando o calculo do Pi no rank: 1\n",
      "Valor parcial do Pi: 1.854590436003130\n",
      "Continuando o calculo do Pi no rank: 2\n",
      "Valor parcial do Pi: 2.574004435173032\n",
      "Continuando o calculo do Pi no rank: 3\n",
      "Valor parcial do Pi: 3.141592653589691\n",
      "Valor de Pi calculado: 3.141592653589691\n",
      "Tempo de execução: 73.058189 segundos\n"
     ]
    }
   ],
   "source": [
    "!mpirun --allow-run-as-root --host localhost:4 -np 4 ./pi"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNy610p2XmV/UhWEz9jfXKw",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
