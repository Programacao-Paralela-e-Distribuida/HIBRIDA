{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Programação Paralela Híbrida: MPI + OpenMP Offloading\n",
        "\n",
        "Autores: *Calebe P. Bianchini, Evaldo B. Costa, Gabriel P. Silva*\n",
        "\n",
        "## Setup de ambiente\n",
        "\n",
        "Para conseguir usar OpenMP em um ambiente híbrido (CPU + GPU), é necessário preparar o kit de ferramentas.\n",
        "\n",
        "Antes de mais nada, verifique se seu ambiente de Google Colab está com o tipo de Runtime usando alguma GPU - veja nos menus disponíveis neste Lab.\n",
        "\n",
        "1. Instale um compilador que consiga usar OpenMP + GPU, como, por exemplo, o GCC-13, e fez o ajuste do ambiente para usá-lo."
      ],
      "metadata": {
        "id": "4I07FwHoBaqk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBSeBifmSn9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l0RumDHAxyr",
        "outputId": "045e3674-6e9c-4587-dea0-f1ff62520075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPA publishes dbgsym, you may need to include 'main/debug' component\r\n",
            "Repository: 'deb https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu/ jammy main'\r\n",
            "Description:\r\n",
            "Toolchain test builds; see https://wiki.ubuntu.com/ToolChain\r\n",
            "\r\n",
            "More info: https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test\r\n",
            "Adding repository.\n",
            "Found existing deb entry in /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
            "Adding deb entry to /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
            "Found existing deb-src entry in /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/ubuntu-toolchain-r-ubuntu-test-jammy.list\n",
            "Adding key to /etc/apt/trusted.gpg.d/ubuntu-toolchain-r-ubuntu-test.gpg with fingerprint C8EC952E2A0E1FBDC5090F6A2C277A0A352154E5\n",
            "Get:1 file:/var/cuda-repo-wsl-ubuntu-12-6-local  InRelease [1572 B]\n",
            "Get:1 file:/var/cuda-repo-wsl-ubuntu-12-6-local  InRelease [1572 B]\n",
            "Hit:2 https://developer.download.nvidia.com/hpc-sdk/ubuntu/amd64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/ubuntu-toolchain-r/test/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2311 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2075 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main Translation-en [386 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2940 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted Translation-en [514 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1183 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe Translation-en [290 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main Translation-en [324 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2836 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted Translation-en [498 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [961 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe Translation-en [205 kB]\n",
            "Fetched 14.9 MB in 6s (2442 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install -y gcc-13 g++-13 gcc-13-offload-nvptx libgomp1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXcokYsEYpF",
        "outputId": "320efc61-aac7-4c47-e824-d7959925c3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "g++-13 is already the newest version (13.1.0-8ubuntu1~22.04).\n",
            "gcc-13 is already the newest version (13.1.0-8ubuntu1~22.04).\n",
            "gcc-13-offload-nvptx is already the newest version (13.1.0-8ubuntu1~22.04).\n",
            "libgomp1 is already the newest version (13.1.0-8ubuntu1~22.04).\n",
            "libgomp1 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo ln -sfnv /usr/bin/gcc-13 /usr/bin/gcc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqKjzpw0Gpsd",
        "outputId": "d37f3025-975e-409d-e4e4-138def9cb92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/usr/bin/gcc' -> '/usr/bin/gcc-13'\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Verifique se os compiladors para OpenMP e GPU estão todos disponíveis. No nosso caso, usaremos o GCC-13 e a versão já instalada do NVidia CUDA:"
      ],
      "metadata": {
        "id": "V0K1s7zOFwno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc --version\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1aYOFLWEb0b",
        "outputId": "5d8034f0-6b99-4dd2-8347-0aaff875de52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gcc (Ubuntu 13.1.0-8ubuntu1~22.04) 13.1.0\r\n",
            "Copyright (C) 2023 Free Software Foundation, Inc.\r\n",
            "This is free software; see the source for copying conditions.  There is NO\r\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
            "\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Fri_Jun_14_16:34:21_PDT_2024\n",
            "Cuda compilation tools, release 12.6, V12.6.20\n",
            "Build cuda_12.6.r12.6/compiler.34431801_0\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kunrecognized command-line option ‘\u001b[01m\u001b[K--showme:version\u001b[m\u001b[K’\n",
            "Wed Jan 29 16:04:46 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.134                Driver Version: 553.35         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Teste seu ambiente"
      ],
      "metadata": {
        "id": "xVR9TFoLH28U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "\n",
        "int main() {\n",
        "  int numdevices = omp_get_num_devices();\n",
        "  int device= omp_get_device_num();\n",
        "  int max_threads = omp_get_max_threads();\n",
        "  printf(\"number of devices= %d *** device= %d\\n\", numdevices, device);\n",
        "  printf(\"max number of threads: %d\\n\", max_threads);\n",
        "}"
      ],
      "metadata": {
        "id": "svasOPN2F91p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b246638-e73f-4af3-d6f6-32d60fc3f75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado deverá ser o número de núcleos disponíveis no seu computador e a quantidade de GPUS."
      ],
      "metadata": {
        "id": "D9NjEAr-aD9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -fopenmp test.c -o test\n",
        "!./test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTDMWO2LH7QI",
        "outputId": "4ae712cc-8b29-422b-9b9e-45d96311d36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of devices= 1 *** device= 1\r\n",
            "max number of threads: 22\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando o tempo de execução da versão sequencial."
      ],
      "metadata": {
        "id": "HErZla7BaRZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -o ./bin/calc_pi ./src/calc_pi.c\n",
        "!./bin/calc_pi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q23VQ1cpZ21H",
        "outputId": "746a094b-4cc6-4d42-a2f7-b5c022e433dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pi = 3.141592653589451, 10000000000 passos, computados em 18.467919 segundos\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora verificando o código da versão com OpenMP offloading, que faz a descarga do laço para execução no acelerador (GPU)."
      ],
      "metadata": {
        "id": "qLzv97-MaX93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cat src/omp_off_calc_pi.c\n"
      ],
      "metadata": {
        "id": "1UQnXJbsIFzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29421b1d-15bc-4489-a895-4cbaafaff737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#include <stdio.h>\r\n",
            "#include <omp.h>\r\n",
            "#include <math.h>\r\n",
            "int main() {\r\n",
            "  long int num_passos = 10000000000; // Número de passos para a integração\r\n",
            "  double passo = 1.0 / (double) num_passos;\r\n",
            "  double pi = 0.0, inicio, fim;\r\n",
            "  inicio = omp_get_wtime();\r\n",
            "  #pragma omp target data map(tofrom: pi) map(to:num_passos, passo) device(1)// Diretiva para offloading para a GPU\r\n",
            "  #pragma omp target teams distribute parallel for reduction(+:pi) // Paralelização com OpenMP\r\n",
            "     for (long int i = 0; i < num_passos; i++) {\r\n",
            "          double x = (i + 0.5) * passo;\r\n",
            "          pi += 4.0 / (double) (1.0 + x * x); \r\n",
            "     }\r\n",
            "  pi *= passo;\r\n",
            "  fim = omp_get_wtime();\r\n",
            "  printf(\"Valor de Pi calculado: %2.15f\\n\", pi);\r\n",
            "  printf(\"Tempo de execução: %f segundos\\n\", fim - inicio);\r\n",
            "  return 0;\r\n",
            "}\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilando e executando com as opções necessárias. Veja a diferença no tempo de execução."
      ],
      "metadata": {
        "id": "1Rt1hHWkamMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -fopenmp -fno-lto -fstack-protector -o bin/omp_off_calc_pi src/omp_off_calc_pi.c\n",
        "!./bin/omp_off_calc_pi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB9qxRdyVkuT",
        "outputId": "811ba0b2-f808-480a-a2e7-28725b209459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor de Pi calculado: 3.141592653589809\r\n",
            "Tempo de execução: 2.376862 segundos\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando o código com MPI e OpenMP threads para execução do cálculo de Pi."
      ],
      "metadata": {
        "id": "_spHRY_Thlum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat src/mpi_omp_calc_pi.c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRJ0Ot4Ph1iH",
        "outputId": "481af8b8-c7ef-42fb-baf0-7d51f15c59bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#include <stdio.h>\r\n",
            "#include \"mpi.h\"\r\n",
            "#include <omp.h>\r\n",
            "static long num_passos = 10000000000;\r\n",
            "double passo;\r\n",
            "int main(int argc, char *argv[])\r\n",
            "{\r\n",
            "  int ranque, numprocs, provided;\r\n",
            "  double x, pi, soma = 0.0, soma_global = 0.0;\r\n",
            "  double inicio, tempo;\r\n",
            "  // Inicia o MPI com suporte para threads\r\n",
            "  MPI_Init_thread(&argc, &argv, MPI_THREAD_FUNNELED, &provided);\r\n",
            "  if (provided < MPI_THREAD_FUNNELED) {\r\n",
            "    printf(\"Nível de suporte para threads não é suficiente!\\n\");\r\n",
            "    MPI_Abort(MPI_COMM_WORLD, 1);\r\n",
            "  }\r\n",
            "  MPI_Comm_rank(MPI_COMM_WORLD, &ranque); // O rank do processo\r\n",
            "  MPI_Comm_size(MPI_COMM_WORLD, &numprocs); // O número de processos\r\n",
            "  passo = 1.0 / (double)num_passos;\r\n",
            "  inicio = omp_get_wtime(); // Tempo de início da execução\r\n",
            "// OpenMP com paralelismo de threads dentro do processo\r\n",
            "#pragma omp parallel for private(x) shared(ranque, num_passos, numprocs, passo) reduction(+:soma) num_threads(4)\r\n",
            "  for (long int i = ranque; i < num_passos; i += numprocs) { // Saltos de acordo com o número de processos\r\n",
            "    x = (i + 0.5) * passo;\r\n",
            "    soma += 4.0 / (1.0 + x * x);\r\n",
            "  }\r\n",
            "  // MPI_Reduce para somar os resultados de todos os processos MPI\r\n",
            "  printf(\"Processo %d Redução %f \\n\", ranque, soma);\r\n",
            "  MPI_Reduce(&soma, &soma_global, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);\r\n",
            "  if (ranque == 0) {\r\n",
            "    pi = passo * soma_global; // Só o processo 0 calcula o valor final de Pi\r\n",
            "    tempo = omp_get_wtime() - inicio;\r\n",
            "    printf(\"pi = %3.15f, %ld passos, computados em %lf segundos\\n\", pi, num_passos, tempo);\r\n",
            "  }  \r\n",
            "  MPI_Finalize(); // Finaliza o MPI\r\n",
            "  return 0;\r\n",
            "}\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilando e executando com MPI e OpenMP threads."
      ],
      "metadata": {
        "id": "p1obQypZh5jU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -fopenmp -fno-lto -fstack-protector src/mpi_omp_calc_pi.c -Wall -o bin/mpi_omp_calc_pi\n",
        "!mpirun -np 4 bin/mpi_omp_calc_pi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8We8GjWdbTBJ",
        "outputId": "2ad46f6f-972e-464a-e02b-adcf099d91f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processo 2 Redução 7853981633.724379 \n",
            "Processo 0 Redução 7853981634.724530 \n",
            "Processo 3 Redução 7853981633.224398 \n",
            "Processo 1 Redução 7853981634.224747 \n",
            "pi = 3.141592653589806, 10000000000 passos, computados em 2.177759 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat src/mpi_omp_off_calc_pi.c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuoU411ZkDV5",
        "outputId": "e3b4b18c-3d50-44f5-a205-68342a1dcadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#include <stdio.h>\r\n",
            "#include \"mpi.h\"\r\n",
            "#include <omp.h>\r\n",
            "static long num_passos = 10000000000;\r\n",
            "double passo;\r\n",
            "int main(int argc, char *argv[])\r\n",
            "{\r\n",
            "  int ranque, numprocs, provided;\r\n",
            "  double x, pi, soma = 0.0, soma_global = 0.0;\r\n",
            "  double inicio, tempo;\r\n",
            "  // Inicia o MPI com suporte para threads\r\n",
            "  MPI_Init_thread(&argc, &argv, MPI_THREAD_FUNNELED, &provided);\r\n",
            "  if (provided < MPI_THREAD_FUNNELED) {\r\n",
            "    printf(\"Nível de suporte para threads não é suficiente!\\n\");\r\n",
            "    MPI_Abort(MPI_COMM_WORLD, 1);\r\n",
            "  }\r\n",
            "  MPI_Comm_rank(MPI_COMM_WORLD, &ranque); // O rank do processo\r\n",
            "  MPI_Comm_size(MPI_COMM_WORLD, &numprocs); // O número de processos\r\n",
            "  passo = 1.0 / (double)num_passos;\r\n",
            "  inicio = omp_get_wtime(); // Tempo de início da execução\r\n",
            "// Offloading com OpenMP para o acelerador (GPU), com paralelismo dentro do processo\r\n",
            "#pragma omp target data map(tofrom:soma) map(to:numprocs, num_passos, ranque, passo) map(alloc:x) device(1)\r\n",
            "#pragma omp target teams distribute parallel for reduction(+:soma) \r\n",
            "  for (long int i = ranque; i < num_passos; i += numprocs) { // Saltos de acordo com o número de processos\r\n",
            "    double x = (i + 0.5) * passo;\r\n",
            "    soma += 4.0 / (1.0 + x * x);\r\n",
            "  }\r\n",
            "  // MPI_Reduce para somar os resultados de todos os processos MPI\r\n",
            "  printf(\"Processo %d Redução %f \\n\", ranque, soma);\r\n",
            "  MPI_Reduce(&soma, &soma_global, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);\r\n",
            "  if (ranque == 0) {\r\n",
            "    pi = passo * soma_global; // Só o processo 0 calcula o valor final de Pi\r\n",
            "    tempo = omp_get_wtime() - inicio;\r\n",
            "    printf(\"pi = %3.15f, %ld passos, computados em %lf segundos\\n\", pi, num_passos, tempo);\r\n",
            "  }  \r\n",
            "  MPI_Finalize(); // Finaliza o MPI\r\n",
            "  return 0;\r\n",
            "}\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilando e executando com MPI + OpenMP Offloading."
      ],
      "metadata": {
        "id": "Pn3zo5hbi6lI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -fopenmp -fno-lto -fstack-protector -o bin/mpi_omp_off_calc_pi src/mpi_omp_off_calc_pi.c\n",
        "!mpirun -np 4 ./bin/mpi_omp_off_calc_pi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDs1pSqObgMb",
        "outputId": "d067fa2b-c620-4ce6-f4a8-1907a05458c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pi = 3.141592653589794, 10000000000 passos, computados em 2.240136 segundos\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat src/mpi_omp_bal_calc_pi.c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4TZ48km0dJk",
        "outputId": "ef6eefea-f551-4387-d29b-4c44f3da42d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#include <stdio.h>\r\n",
            "#include \"mpi.h\"\r\n",
            "#include <omp.h>\r\n",
            "#include <stdlib.h>\r\n",
            "#include <time.h>\r\n",
            "// Defina a proporção da carga de trabalho para a GPU (em %)\r\n",
            "#define GPU_WORKLOAD 70\r\n",
            "static long num_passos = 10000000000; // Número total de pontos aleatórios\r\n",
            "int main(int argc, char *argv[]) {\r\n",
            "    long int gpu_contagem_local = 0, cpu_contagem_local = 0, contagem_global = 0;\r\n",
            "    int ranque, numprocs, provided;\r\n",
            "    double x, y, z, pi;\r\n",
            "    double inicio, tempo;\r\n",
            "    // Inicializa o MPI com suporte para threads\r\n",
            "    MPI_Init_thread(&argc, &argv, MPI_THREAD_FUNNELED, &provided);\r\n",
            "    if (provided < MPI_THREAD_FUNNELED) {\r\n",
            "        printf(\"Nível de suporte para threads não é suficiente!\\n\");\r\n",
            "        MPI_Abort(MPI_COMM_WORLD, 1);\r\n",
            "    }\r\n",
            "    MPI_Comm_rank(MPI_COMM_WORLD, &ranque); // O rank do processo\r\n",
            "    MPI_Comm_size(MPI_COMM_WORLD, &numprocs); // O número de processos\r\n",
            "    // Inicializa o gerador de números aleatórios\r\n",
            "    srand(time(NULL) + ranque);\r\n",
            "    // Define a carga de trabalho para a GPU e para as threads CPU\r\n",
            "    long int passos_gpu = num_passos * GPU_WORKLOAD / 100;\r\n",
            "    long int passos_cpu = num_passos - passos_gpu;\r\n",
            "    inicio = omp_get_wtime(); // Tempo de início da execução\r\n",
            "    // Offloading com OpenMP para a GPU - Master thread\r\n",
            "    #pragma omp parallel num_threads(9)\r\n",
            "    {\r\n",
            "        // Thread master para comunicação e offloading para a GPU\r\n",
            "        #pragma omp master\r\n",
            "        #pragma omp target data map(tofrom:gpu_contagem_local) device(1)\r\n",
            "        #pragma omp target teams distribute parallel for nowait reduction(+:gpu_contagem_local)\r\n",
            "            for (long int i = ranque; i < passos_gpu; i += numprocs) {\r\n",
            "                x = (double)rand() / RAND_MAX;\r\n",
            "                y = (double)rand() / RAND_MAX;\r\n",
            "                z = x * x + y * y;\r\n",
            "                if (z <= 1.0) gpu_contagem_local++; // Verifica se o ponto está no círculo\r\n",
            "            }\r\n",
            "            // Threads secundárias para execução no CPU\r\n",
            "        #pragma omp for reduction(+:cpu_contagem_local)\r\n",
            "            for (long int i = ranque; i < passos_cpu; i += numprocs) {\r\n",
            "                x = (double)rand() / RAND_MAX;\r\n",
            "                y = (double)rand() / RAND_MAX;\r\n",
            "                z = x * x + y * y;\r\n",
            "                if (z <= 1.0) cpu_contagem_local++;\r\n",
            "            }\r\n",
            "    }\r\n",
            "    // MPI_Reduce para somar os resultados de todos os processos MPI\r\n",
            "    long int local_count_total = gpu_contagem_local + cpu_contagem_local;\r\n",
            "    MPI_Reduce(&local_count_total, &contagem_global, 1, MPI_LONG, MPI_SUM, 0, MPI_COMM_WORLD);\r\n",
            "    if (ranque == 0) {\r\n",
            "        pi = ((double)contagem_global / (double)num_passos) * 4.0; // Estimação de Pi\r\n",
            "        tempo = omp_get_wtime() - inicio;\r\n",
            "        printf(\"pi = %3.15f, %ld amostras, computados em %lf segundos\\n\", pi, num_passos, tempo);\r\n",
            "    }\r\n",
            "    MPI_Finalize(); // Finaliza o MPI\r\n",
            "    return 0;\r\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -fopenmp -fno-lto -fstack-protector -o bin/mpi_omp_bal_calc_pi src/mpi_omp_bal_calc_pi.c\n",
        "!mpirun -np 4 ./bin/mpi_omp_bal_calc_pi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoVbfJ1p0khT",
        "outputId": "0f0ee427-6324-4fed-a9cc-b4424bf5fe43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pi = 3.141827072000000, 1000000000 amostras, computados em 44.408770 segundos\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Números Primos\n",
        "O programa em questão serve para determinar a quantidade de números primos entre 0 e um determinado valor inteiro N.\n",
        "Embora possa parecer um programa trivial a princípio, ele tem algumas particularidades que o tornam um problema interessante.\n",
        "Na matemática, o Teorema do Número Primo (TNP) descreve a distribuição assintótica dos números primos entre os inteiros positivos.\n",
        "Ele formaliza a ideia intuitiva de que os números primos tornam-se menos comuns à medida que N aumenta, quantificando precisamente a taxa em que isso ocorre.\n",
        "<p>\n",
        "Bom, a nossa primeira tentativa de paralelização seria dividir o total de N números igualmente entre os P processadores disponíveis, ou seja, N/P valores para cada uma dos processos ou threads.\n",
        "No entanto, há uma implicação importante: a distribuição dos números primos não é uniforme entre os inteiros.\n",
        "Esse fato mostra que a divisão direta é ineficaz, pois os processos ou threads que receberem intervalos com uma maior concentração de números primos terão uma carga de trabalho significativamente maior."
      ],
      "metadata": {
        "id": "7TP0c5V-iHJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat src/seq_primos.c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G-OYTqgVYZS",
        "outputId": "93e1d664-3bc9-486d-efa2-bcc2b60a557e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#include <stdio.h>\r\n",
            "#include <stdbool.h>\r\n",
            "#include <math.h>\r\n",
            "\r\n",
            "// Função para verificar se um número é primo\r\n",
            "bool is_prime(int num) {\r\n",
            "    if (num <= 1) return false;\r\n",
            "    if (num == 2) return true;\r\n",
            "    if (num % 2 == 0) return false;\r\n",
            "\r\n",
            "    for (int i = 3; i <= sqrt(num); i += 2) {\r\n",
            "        if (num % i == 0) return false;\r\n",
            "    }\r\n",
            "    return true;\r\n",
            "}\r\n",
            "\r\n",
            "int main() {\r\n",
            "    long int N, total_primes=0;\r\n",
            "    printf(\"Digite o valor de N: \");\r\n",
            "    scanf(\"%ld\", &N);\r\n",
            "\r\n",
            "    // Dividir o trabalho entre CPU e GPU\r\n",
            "    for (int i = 1; i <= N ; i+=2) {\r\n",
            "         if (is_prime(i)) {\r\n",
            "             total_primes++;\r\n",
            "         }\r\n",
            "    }\r\n",
            "    total_primes++;  // O número 2 também é primo\r\n",
            "\r\n",
            "    // Soma os resultados da CPU e GPU\r\n",
            "\r\n",
            "    printf(\"Total de números primos entre 1 e %ld: %ld\\n\", N, total_primes);\r\n",
            "    return 0;\r\n",
            "}\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -fopenmp -o bin/seq_primos src/seq_primos.c\n",
        "!time ./bin/seq_primos 100000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeZ_Fevl3EbK",
        "outputId": "be9d1b20-fa41-4d68-cae6-e216495c3dfa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de números primos entre 1 e 100000000: 5761455\r\n",
            "\r\n",
            "real\t1m5.311s\r\n",
            "user\t1m5.312s\r\n",
            "sys\t0m0.000s\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Versão com OpenMP offloading\n",
        "\n",
        "A seguir a versão com OpenMP offloading, com balanceamento de carga para os núcleos também."
      ],
      "metadata": {
        "id": "5xSxVRZ-3YoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat src/omp_off_primos.c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUliR9G02meb",
        "outputId": "21ed03d7-a4a7-42bb-e59c-0e4165a31c3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#include <stdio.h>\r\n",
            "#include <stdbool.h>\r\n",
            "#include <stdlib.h>\r\n",
            "#include <math.h>\r\n",
            "#include <omp.h>\r\n",
            "\r\n",
            "// Função para verificar se um número é primo\r\n",
            "bool is_prime2(int num) {\r\n",
            "    for (int i = 3; i <= sqrt(num); i += 2) {\r\n",
            "        if (num % i == 0) return false;\r\n",
            "    }\r\n",
            "    return true;\r\n",
            "}\r\n",
            "\r\n",
            "bool is_prime(long int n) {\r\n",
            "    if (n <= 3) return true;\r\n",
            "    if (n % 2 == 0 || n % 3 == 0) return false;\r\n",
            "    for (long int i = 5; i * i <= n; i += 6) {\r\n",
            "        if (n % i == 0 || n % (i + 2) == 0) return false;\r\n",
            "    }\r\n",
            "    return true;\r\n",
            "}\r\n",
            "\r\n",
            "int main(int argc, char *argv[]) {\r\n",
            "int N;\r\n",
            "    if (argc < 2) {\r\n",
            "        printf(\"Valor inválido! Entre com o valor do maior inteiro\\n\");\r\n",
            "       \treturn 0;\r\n",
            "    } else {\r\n",
            "        N = strtol(argv[1], (char **) NULL, 10);\r\n",
            "    }\r\n",
            "\r\n",
            "    int total_primes_cpu = 0;\r\n",
            "    int total_primes_gpu = 0;\r\n",
            "\r\n",
            "    // Dividir o trabalho entre CPU e GPU\r\n",
            "    int split_point = (int)(N * .3); // 30% para CPU, 70% para GPU\r\n",
            "    if (split_point % 2 != 0) \r\n",
            "        split_point--; // Se for ímpar, subtrai 1 para tornar par\r\n",
            "    double inicio = omp_get_wtime();\r\n",
            "    // Criar duas tarefas assíncronas\r\n",
            "    #pragma omp parallel\r\n",
            "    {\r\n",
            "        #pragma omp master\r\n",
            "        {\r\n",
            "            // Tarefa 1: Processamento na CPU\r\n",
            "            #pragma omp task shared(total_primes_cpu, split_point)\r\n",
            "            #pragma omp parallel for reduction(+:total_primes_cpu) num_threads(16)\r\n",
            "            for (int i = 3; i <= split_point; i +=2) {\r\n",
            "                 if (is_prime(i)) \r\n",
            "                    total_primes_cpu++;\r\n",
            "            }\r\n",
            "\r\n",
            "            // Tarefa 2: Processamento na GPU\r\n",
            "            #pragma omp task shared(total_primes_gpu, split_point)\r\n",
            "            #pragma omp target teams distribute parallel for reduction(+:total_primes_gpu) map(tofrom: total_primes_gpu)\r\n",
            "            for (int i = split_point + 1; i <= N; i+=2) {\r\n",
            "                if (is_prime(i)) \r\n",
            "                    total_primes_gpu++;\r\n",
            "            }\r\n",
            "            // Aguardar a conclusão das duas tarefas\r\n",
            "            #pragma omp taskwait\r\n",
            "        }\r\n",
            "    }\r\n",
            "\r\n",
            "    // Soma os resultados da CPU e GPU\r\n",
            "    int total_primes = total_primes_cpu + total_primes_gpu;\r\n",
            "    total_primes++; // Adiciona o número 2, que não foi verificado\r\n",
            "    double tempo = omp_get_wtime() - inicio;\r\n",
            "    printf(\"Total de números primos entre 1 e %d: %d. Calculado em %f segundos.\\n\", N, total_primes, tempo);\r\n",
            "    printf(\"Primos encontrados na CPU: %d\\n\", total_primes_cpu);\r\n",
            "    printf(\"Primos encontrados na GPU: %d\\n\", total_primes_gpu);\r\n",
            "    printf(\"Ponto de Divisão: %d\\n\", split_point);\r\n",
            "    return 0;\r\n",
            "}\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -fopenmp -fno-lto -fstack-protector -o bin/omp_off_primos src/omp_off_primos.c -lm\n",
        "!./bin/omp_off_primos 100000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfLa5PLXF333",
        "outputId": "4aaaa64a-ab10-43db-944f-578377c8064a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de números primos entre 1 e 100000000: 5761455. Calculado em 13.524612 segundos.\r\n",
            "Primos encontrados na CPU: 1857858\r\n",
            "Primos encontrados na GPU: 3903596\r\n",
            "Ponto de Divisão: 30000000\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Versão com MPI e  OpenMP offloading\n",
        "\n",
        "A seguir a versão com MPI e OpenMP offloading, com balanceamento de carga para os núcleos também."
      ],
      "metadata": {
        "id": "JPAyYAo33up8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat src/mpi_off_primos.c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jWL6elR220X",
        "outputId": "6858041f-be7e-4b3d-8ed4-f60f562d5657"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#include <stdio.h>\r\n",
            "#include <stdlib.h>\r\n",
            "#include <math.h>\r\n",
            "#include <omp.h>\r\n",
            "#include <mpi.h>\r\n",
            "\r\n",
            "int is_prime(long int n) {\r\n",
            "    if (n <= 1) return 0;\r\n",
            "    if (n <= 3) return 1;\r\n",
            "    if (n % 2 == 0 || n % 3 == 0) return 0;\r\n",
            "    for (long int i = 5; i * i <= n; i += 6) {\r\n",
            "        if (n % i == 0 || n % (i + 2) == 0) return 0;\r\n",
            "    }\r\n",
            "    return 1;\r\n",
            "}\r\n",
            "#define GPU_WORKLOAD 70\r\n",
            "\r\n",
            "int main(int argc, char *argv[]) {\r\n",
            "    int numprocs, rank, salto;\r\n",
            "    long int num_primes_gpu = 0, num_primes_cpu = 0, global_num_primes = 0;\r\n",
            "    long int  n, i, gpu_end;\r\n",
            "    double start_time, end_time;\r\n",
            "\r\n",
            "    MPI_Init(&argc, &argv);\r\n",
            "    MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\r\n",
            "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\r\n",
            "\r\n",
            "    if (argc < 2) {\r\n",
            "        printf(\"Valor inválido! Entre com o valor do maior inteiro\\n\");\r\n",
            "       \treturn 0;\r\n",
            "    } else {\r\n",
            "        n = strtol(argv[1], (char **) NULL, 10);\r\n",
            "    }\r\n",
            "\r\n",
            "    gpu_end = n  * GPU_WORKLOAD / 100;\r\n",
            "    if (gpu_end % 2 != 0) {\r\n",
            "        gpu_end--; // Se for ímpar, subtrai 1 para tornar par\r\n",
            "    }\r\n",
            "    salto = numprocs*2;\r\n",
            "\r\n",
            "    start_time = omp_get_wtime();\r\n",
            "\r\n",
            "    #pragma omp parallel\r\n",
            "    {\r\n",
            "        #pragma omp master\r\n",
            "        {\r\n",
            "            // Tarefa 1: Processamento na GPU\r\n",
            "        #pragma omp task shared(num_primes_gpu, rank, n)\r\n",
            "        {\r\n",
            "        #pragma omp target data map(tofrom:num_primes_gpu) device(1)\r\n",
            "        #pragma omp target teams distribute parallel for reduction(+:num_primes_gpu)\r\n",
            "            for (long int i = 3+(rank*2); i <= gpu_end; i += salto) {\r\n",
            "                if (is_prime(i)) num_primes_gpu++;\r\n",
            "            }\r\n",
            "        }\r\n",
            "          // Tarefa 1: Processamento na CPU\r\n",
            "        #pragma omp task shared(num_primes_cpu, rank, n)\r\n",
            "        #pragma omp parallel for reduction(+:num_primes_cpu) num_threads(4)\r\n",
            "            for (long int j = gpu_end+(rank*2)+1; j <= n; j += salto) {\r\n",
            "                if (is_prime(j)) num_primes_cpu++;\r\n",
            "            }\r\n",
            "        }\r\n",
            "    }\r\n",
            "    long int local_num_primes = num_primes_gpu + num_primes_cpu;\r\n",
            "    printf(\"Total local %d  %ld\\n\", rank, local_num_primes);\r\n",
            "    MPI_Reduce(&local_num_primes, &global_num_primes, 1, MPI_LONG, MPI_SUM, 0, MPI_COMM_WORLD);\r\n",
            "    global_num_primes++; // Adiciona 2, que é o único número par primo\r\n",
            "    if (rank == 0) {\r\n",
            "        end_time = omp_get_wtime();\r\n",
            "        printf(\"Total de primos até %ld: %ld\\n\", n, global_num_primes);\r\n",
            "        printf(\"Calculado em %lf segundos\\n\", end_time - start_time);\r\n",
            "    }\r\n",
            "    MPI_Finalize();\r\n",
            "    return 0;\r\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -fopenmp -fno-lto -fstack-protector -o bin/mpi_off_primos src/mpi_off_primos.c\n",
        "!mpirun -np 4 ./bin/mpi_off_primos 100000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPPPfJqhLq2R",
        "outputId": "3f04ded4-cd6f-436a-8881-1dd21a8bb1e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total local 2  1440529\n",
            "Total local 1  1440666\n",
            "Total local 0  1440602\n",
            "Total local 3  1439657\n",
            "Total de primos até 100000000: 5761455\n",
            "Calculado em 8.697654 segundos\n"
          ]
        }
      ]
    }
  ]
}